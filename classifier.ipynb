{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ignore warnings.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Audio processing\n",
    "from scipy.io import wavfile\n",
    "\n",
    "# maths and sci libraries.\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "# for dict and all.\n",
    "import collections\n",
    "\n",
    "# for plotting.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# signal processing\n",
    "from scipy.io                     import wavfile\n",
    "from scipy                        import stats, signal\n",
    "from scipy.fftpack                import fft\n",
    "\n",
    "from scipy.signal                 import lfilter, hamming\n",
    "from scipy.fftpack.realtransforms import dct\n",
    "from scikits.talkbox              import segment_axis\n",
    "from scikits.talkbox.features     import mfcc\n",
    "\n",
    "\n",
    "# encoding purpose.\n",
    "from base64 import b64decode\n",
    "\n",
    "#pandas for csvs.\n",
    "import pandas as pd\n",
    "\n",
    "# import stft\n",
    "import stft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create the audio files path.\n",
    "audio_file = collections.defaultdict(dict)\n",
    "\n",
    "# initialise the audio songs as (genre, path).\n",
    "# where path is path of the current .wav audio.\n",
    "\n",
    "audio_file[\"rock\"][\"path\"] = r\"tomydeepestego.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def audio_length():\n",
    "    samplerate, wavedata = wavfile.read(audio_file[\"rock\"][\"path\"])\n",
    "    audio_file[\"rock\"][\"wavedata\"] = wavedata\n",
    "    audio_file[\"rock\"][\"samplerate\"] = samplerate\n",
    "    number_of_samples = wavedata.shape[0]\n",
    "    print samplerate, wavedata.shape[0]\n",
    "    # song length : number of samples/samplerate.\n",
    "    print \"Audio length: \" + str(number_of_samples/samplerate) + \" seconds\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44100 16181864\n",
      "Audio length: 366 seconds\n"
     ]
    }
   ],
   "source": [
    "audio_length()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def wavedata_mean():\n",
    "    audio_file[\"rock\"][\"wavedata\"] = np.mean(audio_file[\"rock\"][\"wavedata\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wavedata_mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\" Zero Crossing Rate : Is a time domain feature.\n",
    "    Simple, straightforward and inexpensive feature to examine the similarity between two sets of time series.\n",
    "    It is the number of times signal changes sign. It is useful for signals affected by noise.\n",
    "\"\"\"\n",
    "def zero_crossing_rate_bruteForce(wavedata):\n",
    "    zero_crossing = 0\n",
    "    for i in range(1, number_of_samples):\n",
    "        if (wavedata[i-1] < 0 and wavedata[i]>0) or (wavedata[i-1] > 0 and wavedata[i] < 0) or (wavedata[i-1] != 0 and wavedata[i] == 0):\n",
    "            zero_crossing += 1;\n",
    "    zero_crossing_rate = zero_crossing / float(number_of_samples-1)\n",
    "    return zero_crossing_rate\n",
    "\n",
    "\n",
    "def zero_crossing_rate(wavedata, block_length, sample_rate):\n",
    "    # Number of blocks required.\n",
    "    num_blocks = int(np.ceil(len(wavedata)/block_length))\n",
    "    \n",
    "    # Timestamps for the beginning of the blocks.\n",
    "    timestamps = (np.arange(0, num_blocks - 1) * (block_length/float(sample_rate)))\n",
    "    \n",
    "    zcr = []\n",
    "    for i in range(0, num_blocks - 1):\n",
    "        start = i*block_length\n",
    "        stop = np.min([(start + block_length - 1), len(wavedata)])\n",
    "        zc = 0.5*np.mean(np.abs(np.diff(np.sign(wavedata[start:stop]))))\n",
    "        zcr.append(zc)\n",
    "        \n",
    "    return np.asarray(zcr), np.asarray(timestamps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zcr, zcr_timestamps = zero_crossing_rate(audio_file[\"rock\"][\"wavedata\"], 1024, audio_file[\"rock\"][\"samplerate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.        , ...,  0.02446184,\n",
       "        0.04354207,  0.03620352])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zcr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f4d25464b50>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(zcr_timestamps, zcr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" Root mean Square : comparing arbitary waveforms based upon \n",
    "    their equivalent energy.\"\"\"\n",
    "def root_mean_square(wavedata, block_length, sample_rate):\n",
    "    num_blocks = int(np.ceil(len(wavedata)/block_length))\n",
    "    \n",
    "    timestamps = (np.arange(0, num_blocks-1) * (block_length/float(sample_rate)))\n",
    "    \n",
    "    rms = []\n",
    "    \n",
    "    for i in range(0, num_blocks-1):\n",
    "        start = i*block_length\n",
    "        stop = np.min([(start + block_length -1), len(wavedata)])\n",
    "        \n",
    "        rms_seg = np.sqrt(np.mean(wavedata[start:stop]**2))\n",
    "        rms.append(rms_seg)\n",
    "    return np.asarray(rms), np.asarray(timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rms, rms_timestamps = root_mean_square(audio_file[\"rock\"][\"wavedata\"], 1024, audio_file[\"rock\"][\"samplerate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f4d25464590>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(rms_timestamps, rms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" Spectral features. \"\"\"\n",
    "\"\"\" Spectral centroid : centre of gravity.\n",
    "    Tells the frequency around which most of the signal energy is concentrated.\n",
    "    Tells how dark/bright the sound is.\"\"\"\n",
    "def spectral_centroid(wavedata, window_size, sample_rate):\n",
    "    magnitude_spectrum = stft.spectrogram(wavedata, window_size)\n",
    "    timebins, freqbins = np.shape(magnitude_spectrum)\n",
    "    timestamps = (np.arange(0, timebins - 1)*(timebins/float(sample_rate)))\n",
    "    spec_centroid = []\n",
    "    \n",
    "    for t in range(timebins - 1):\n",
    "        power_spectrum = np.abs(magnitude_spectrum[t])**2\n",
    "        \n",
    "        sc_t = np.sum(power_spectrum * np.arange(1, freqbins + 1))/np.sum(power_spectrum)\n",
    "        \n",
    "        spec_centroid.append(sc_t)\n",
    "        \n",
    "    return np.nan_to_num(np.asarray(spec_centroid)), np.asarray(timestamps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spec_centroid, spec_ts = spectral_centroid(audio_file[\"rock\"][\"wavedata\"], 1024, audio_file[\"rock\"][\"samplerate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f4d24b26b90>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(spec_ts, spec_centroid)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\"\"\" Sprectral rolloff :\n",
    "    Nth percentile of the power spectral distribution, \n",
    "    where N is 85% or 95%. The rolloff point is the frequency below which \n",
    "    the N% of the magnitude distribution is concentrated.\n",
    "    Used to distinguish voice speech from unvoiced.\n",
    "    Unvoiced has a high proportion of energy contained in the high-frequency range of the spectrum.\n",
    "    - fraction of bins in the power spectrum at which 85%(N%) of the power is at lower frequencies.\n",
    "\"\"\"\n",
    "def spectral_rolloff(wavedata, window_size, sample_rate, k=0.85):\n",
    "    # convert into frequency domain using short term fourier transform.\n",
    "    magnitude_spectrum = stft.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\" Sprectral rolloff :\n",
    "    Nth percentile of the power spectral distribution, \n",
    "    where N is 85% or 95%. The rolloff point is the frequency below which \n",
    "    the N% of the magnitude distribution is concentrated.\n",
    "    Used to distinguish voice speech from unvoiced.\n",
    "    Unvoiced has a high proportion of energy contained in the high-frequency range of the spectrum.\n",
    "    - fraction of bins in the power spectrum at which 85%(N%) of the power is at lower frequencies.\n",
    "\"\"\"\n",
    "def spectral_rolloff(wavedata, window_size, sample_rate, k=0.85):\n",
    "    # convert into frequency domain using short term fourier transform.\n",
    "    magnitude_spectrum = stft.spectrogram(wavedata, window_size)\n",
    "    time_bins, freq_bins = np.shape(magnitude_spectrum)\n",
    "    power_spectrum = np.abs(magnitude_spectrum)**2\n",
    "    \n",
    "    # create timestamps\n",
    "    timestamps = (np.arange(0, time_bins - 1)*(time_bins/float(sample_rate)))\n",
    "        \n",
    "    spec_rolloff = []\n",
    "    \n",
    "    spectral_sum = np.sum(power_spectrum, axis=1)\n",
    "    \n",
    "    for t in range(time_bins - 1):\n",
    "        # find frequency-bin indices where cummulative sum of all bins is higher than k-percent of the sum of all bins.\n",
    "        # minimum index = rolloff.\n",
    "        spec_rolloff_temp = np.where(np.cumsum(power_spectrum[t, :]) >= k*spectral_sum[t])[0][0]\n",
    "        spec_rolloff.append(spec_rolloff_temp)\n",
    "    \n",
    "    spec_rolloff = np.asarray(spec_rolloff).astype(float)\n",
    "    \n",
    "    spec_rolloff = (spec_rolloff/freq_bins)*(sample_rate/2.0)\n",
    "    \n",
    "    return spec_rolloff, np.asarray(timestamps)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spec_rolloff, spec_ts = spectral_rolloff(audio_file[\"rock\"][\"wavedata\"], 1024, audio_file[\"rock\"][\"samplerate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f4d24dfcd10>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(spec_ts, spec_rolloff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" Spectral flux : squared diff in frequency distribution of two successive time frames.\"\"\"\n",
    "\"\"\" Helps in measuring rate of local change in the spectrum\"\"\"\n",
    "def spectral_flux(wavedata, window_size, sample_rate):\n",
    "    magnitude_spectrum = stft.spectrogram(wavedata, window_size)\n",
    "    time_bins, freq_bins = np.shape(magnitude_spectrum)\n",
    "    \n",
    "    # create timestamps.\n",
    "    timestamps = (np.arange(0, time_bins - 1) * (time_bins/float(sample_rate)))\n",
    "    \n",
    "    spec_flux = np.sqrt(sp.sum(np.diff(np.abs(magnitude_spectrum))**2, axis = 1))/freq_bins\n",
    "    \n",
    "    return spec_flux[1:], np.asarray(timestamps)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spec_flux, spec_flux_ts = spectral_flux(audio_file[\"rock\"][\"wavedata\"], 1024, audio_file[\"rock\"][\"samplerate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f4d24dca6d0>]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(spec_flux_ts, spec_flux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" MFCC : coefficients that collectively make up an MFC.\n",
    "    They are derived from a type of cepstral representation of the audio ( a nonlinear spectrum of a spectrum).\n",
    "    In MFC the frequency bands are equally spaced on the mel scale, which approximates the human auditory systems response more closely than the linear spaced frequency bands.\n",
    "\"\"\"\n",
    "def MFCC_Cal(input_data):\n",
    "    # apply pre-filtering.\n",
    "    \n",
    "    # params\n",
    "    nwin = 256\n",
    "    nfft = 1024\n",
    "    fs = 16000\n",
    "    nceps = 13\n",
    "    \n",
    "    # pre-emphasis factor\n",
    "    prefac = 0.97\n",
    "    \n",
    "    over = nwin - 160\n",
    "    \n",
    "    filtered_data = lfilter([1., -prefac], 1, input_data)\n",
    "    \n",
    "    # compute the spectrum amplitude by windowing with a hamming window.\n",
    "    windows = hamming(256, sym = 0)\n",
    "    framed_data = segment_axis(filtered_data, nwin, over) * windows\n",
    "    \n",
    "    magnitude_spectrum = np.abs(fft(framed_data, nfft, axis = -1))\n",
    "    \n",
    "    \n",
    "    # filter the signal in the spectral domain with a triangular filter-bank, \n",
    "    # whose filters are approximately linearly spaced on the mel scale, and have equal bandwidth in the mel scale/\n",
    "\n",
    "    lowfreq = 133.33\n",
    "    linsc = 200/3\n",
    "    logsc = 1.0711703\n",
    "    fs = 44100\n",
    "    \n",
    "    nlinfilt = 13\n",
    "    nlogfilt = 27\n",
    "    \n",
    "    #total filters \n",
    "    nfilt = nlinfilt + nlogfilt\n",
    "    \n",
    "    # Compute the filter bank.\n",
    "    # compute start/middle/end points of the triangular filters in spectral.\n",
    "    \n",
    "    #domain.\n",
    "    freqs = np.zeros(nfilt + 2)\n",
    "    freqs[:nlinfilt] = lowfreq + np.arange(nlinfilt) * linsc\n",
    "    \n",
    "    freqs[nlinfilt:] = freqs[nlinfilt - 1] * logsc ** np.arange(1, nlogfilt + 3)\n",
    "    \n",
    "    heights = 2./(freqs[2:] - freqs[0:-2])\n",
    "    \n",
    "    #compute filterbank coeff (in fft domain, in bins)\n",
    "    filterbank = np.zeros((nfilt, nfft))\n",
    "    \n",
    "    # FFT bins (in Hz)\n",
    "    nfreqs = np.arange(nfft)/(1. * nfft)*fs\n",
    "    \n",
    "    for i in range(nfilt):\n",
    "        low = freqs[i]\n",
    "        cen = freqs[i+1]\n",
    "        hi = freqs[i+2]\n",
    "        \n",
    "        lid = np.arange(np.floor(low*nfft/fs) + 1,\n",
    "                        np.floor(cen*nfft/fs) + 1, dtype = np.int)\n",
    "        \n",
    "        rid = np.arange(np.floor(cen*nfft/fs) + 1,\n",
    "                        np.floor(hi*nfft/fs) + 1, dtype = np.int)\n",
    "        \n",
    "        lslope = heights[i]/(cen - low)\n",
    "        rslope = heights[i]/(hi-cen)\n",
    "        \n",
    "        filterbank[i][lid] = lslope * (nfreqs[lid] - low)\n",
    "        filterbank[i][rid] = rslope * (hi - nfreqs[rid])\n",
    "        \n",
    "        # filter the spectrum through the triangle filterbank.\n",
    "        \n",
    "        mspec = np.log10(np.dot(magnitude_spectrum, filterbank.T))\n",
    "        \n",
    "        \n",
    "        # Use the DCT to 'compress' the coefficients (spectrum -> cepstrum domain)\n",
    "        MFCCs = dct(mspec, type = 2, norm = 'ortho', axis = -1)[:, :nceps]\n",
    "        \n",
    "        \n",
    "        return MFCCs, mspec, magnitude_spectrum\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MFCCs, mspec, spec = MFCC_Cal(audio_file[\"rock\"][\"wavedata\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" Rhythm patterns : \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
